{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Calibration Stereo Camera</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Distortion causes by Camera</h2>\n",
    "\n",
    "https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of distortion:\n",
    "*   Radial distortion: straight line --> curved. Radial distortion becomes larger the farther points are from the center of the image\n",
    "*   Tangential (Decentering) distortion: causes by the image-taking lense is not aligned perfectly parallel with the imaging plane\n",
    "\n",
    "We need to find 5 params known as **Distortion Coefficients** given by: `DC = (k1 k2 k3 p1 p2 )` (k1 k2 k3) is radial coeffs, (p1 p2) is tangential coeffs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrinsic params of the camera:\n",
    "*   It is specifically assigned to a specific camera\n",
    "*   Focal length $(f_x, f_y)$, optical centers $(c_x, c_y)$\n",
    "\n",
    "Camera matrix\n",
    "$$\n",
    "\\begin{bmatrix} f_x & 0 & c_x \\\\ 0 & f_y & c_y \\\\ 0 & 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Extrinsic params of the camera:\n",
    "*   Rotation and Translation vectors to mapping a 3D point to a coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 10 test patterns for camera calibration\n",
    "''' \n",
    "Input:\n",
    "    The 3D real world points (object points)\n",
    "    The corresponding 2D points in the image (image points)\n",
    "Output:\n",
    "    The Extrinsic params\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chessSize = (9,6)\n",
    "imSize = (640,480)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find Chess Board Corners\n",
    "*   Input: image, size of image, size of chessboard\n",
    "*   Output: Chess board corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# object points\n",
    "objp = np.zeros((chessSize[0]*chessSize[1],3),np.float32)\n",
    "objp[:,:2] = np.mgrid[0:chessSize[0],0:chessSize[1]].T.reshape(-1,2)\n",
    "\n",
    "# Store all the object points and image points from all the images\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpointsL = [] # 2d point in the image plane\n",
    "imgpointsR = [] # 2d point in the image plane\n",
    "\n",
    "imagesLeft = glob.glob('images/stereoLeft/*.png')\n",
    "imagesRight = glob.glob('images/stereoRight/*.png')\n",
    "\n",
    "for fLeft, fRight in zip(imagesLeft, imagesRight):\n",
    "    imgLeft = cv2.imread(fLeft,0)\n",
    "    imgRight = cv2.imread(fRight,0)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    retL, corners = cv2.findChessboardCorners(imgLeft, chessSize, None)\n",
    "    retR, corners = cv2.findChessboardCorners(imgRight, chessSize, None)\n",
    "\n",
    "    # If found, add object points, image points (after refining them)\n",
    "    if retL and retR == True:\n",
    "        objpoints.append(objp)\n",
    "\n",
    "        cornersL = cv2.cornerSubPix(imgLeft,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpointsL.append(cornersL)\n",
    "\n",
    "        cornersR = cv2.cornerSubPix(imgRight,corners, (11,11), (-1,-1), criteria)\n",
    "        imgpointsR.append(cornersR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibration\n",
    "*   Input: Chess board corners\n",
    "*   Output: The camera matrix, DC, rotation & translation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(objpoints, imgpointsL, imSize, None, None)\n",
    "retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(objpoints, imgpointsR, imSize, None, None)\n",
    "\n",
    "heightL, widthL = imgLeft.shape\n",
    "heightR, widthR = imgRight.shape\n",
    "\n",
    "newmtxL, roiL = cv2.getOptimalNewCameraMatrix(mtxL, distL, (widthL, heightL), 1, (widthL, heightL))\n",
    "newmtxR, roiR = cv2.getOptimalNewCameraMatrix(mtxL, distL, (widthL, heightL), 1, (widthL, heightL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo Vision Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = 0\n",
    "flags |= cv2.CALIB_FIX_INTRINSIC\n",
    "\n",
    "# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.\n",
    "# Hence intrinsic parameters are the same \n",
    "\n",
    "criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix\n",
    "retStereo, newmtxL, distL, newmtxR, distR, rot, trans, essentialMatrix, fundamentalMatrix = cv2.stereoCalibrate(objpoints, imgpointsL, imgpointsR, newmtxL, distL, newmtxR, distR, imgLeft.shape[::-1], criteria_stereo, flags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stereo Rectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving parameters!\n"
     ]
    }
   ],
   "source": [
    "rectifyScale= 1\n",
    "rectL, rectR, projMatrixL, projMatrixR, Q, roi_L, roi_R= cv2.stereoRectify(newmtxL, distL, newmtxR, distR, imgLeft.shape[::-1], rot, trans, rectifyScale,(0,0))\n",
    "\n",
    "stereoMapL = cv2.initUndistortRectifyMap(newmtxL, distL, rectL, projMatrixL, imgLeft.shape[::-1], cv2.CV_16SC2)\n",
    "stereoMapR = cv2.initUndistortRectifyMap(newmtxR, distR, rectR, projMatrixR, imgRight.shape[::-1], cv2.CV_16SC2)\n",
    "\n",
    "print(\"Saving parameters!\")\n",
    "cv_file = cv2.FileStorage('stereoMap.xml', cv2.FILE_STORAGE_WRITE)\n",
    "\n",
    "cv_file.write('stereoMapL_x',stereoMapL[0])\n",
    "cv_file.write('stereoMapL_y',stereoMapL[1])\n",
    "cv_file.write('stereoMapR_x',stereoMapR[0])\n",
    "cv_file.write('stereoMapR_y',stereoMapR[1])\n",
    "\n",
    "cv_file.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "099fd5c3e43525b17c255e8ba7b9c5b403e2029f8af62094b64bbe5ae73026c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
